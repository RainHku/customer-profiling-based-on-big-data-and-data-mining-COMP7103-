{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "#Transform to UTF-8\n",
    "\n",
    "data_path = './data/user_tag_query.10W.TRAIN' \n",
    "csvfile = open(data_path + '-1w.csv', 'w')\n",
    "writer = csv.writer(csvfile)\n",
    "writer.writerow(['ID', 'age', 'Gender', 'Education', 'QueryList'])\n",
    "\n",
    "with open(data_path, 'r',encoding='gb18030',errors='ignore') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[0:10000]:\n",
    "        try:\n",
    "            line.strip()          \n",
    "            data = line.split(\"\\t\")\n",
    "            writedata = [data[0], data[1], data[2], data[3]]\n",
    "            querystr = ''\n",
    "            data[-1]=data[-1][:-1]\n",
    "            for d in data[4:]:\n",
    "                try:\n",
    "                    cur_str = d.encode('utf8')\n",
    "                    cur_str = cur_str.decode('utf8')\n",
    "                    querystr += cur_str + '\\t'\n",
    "                except:\n",
    "                    continue\n",
    "                    #print (data[0][0:10])\n",
    "            querystr = querystr[:-1]\n",
    "            writedata.append(querystr)\n",
    "            writer.writerow(writedata)\n",
    "        except:\n",
    "            #print (data[0][0:20])\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/user_tag_query.10W.TEST'\n",
    "\n",
    "csvfile = open(data_path + '-1w.csv', 'w')\n",
    "writer = csv.writer(csvfile)\n",
    "writer.writerow(['ID', 'QueryList'])\n",
    "with open(data_path, 'r',encoding='gb18030',errors='ignore') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[0:10000]:\n",
    "        try:\n",
    "            data = line.split(\"\\t\")\n",
    "            writedata = [data[0]]\n",
    "            querystr = ''\n",
    "            data[-1]=data[-1][:-1]\n",
    "            for d in data[1:]:\n",
    "                try:                  \n",
    "                    cur_str = d.encode('utf8')\n",
    "                    cur_str = cur_str.decode('utf8')\n",
    "                    querystr += cur_str + '\\t'               \n",
    "                except:\n",
    "                    #print (data[0][0:10])\n",
    "                    continue\n",
    "            querystr = querystr[:-1]\n",
    "            writedata.append(querystr)\n",
    "            writer.writerow(writedata)\n",
    "        except:\n",
    "            #print (data[0][0:20])\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9988 entries, 0 to 9987\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ID         9988 non-null   object\n",
      " 1   age        9988 non-null   int64 \n",
      " 2   Gender     9988 non-null   int64 \n",
      " 3   Education  9988 non-null   int64 \n",
      " 4   QueryList  9988 non-null   object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 390.3+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9971 entries, 0 to 9970\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ID         9971 non-null   object\n",
      " 1   QueryList  9971 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 155.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Divide into train and test data\n",
    "trainname = './data/user_tag_query.10W.TRAIN-1w.csv'\n",
    "testname = './data/user_tag_query.10W.TEST-1w.csv'\n",
    "\n",
    "data = pd.read_csv(trainname,encoding='gbk')\n",
    "print (data.info())\n",
    "\n",
    "data.age.to_csv(\"./data/train_age.csv\", index=False)\n",
    "data.Gender.to_csv(\"./data/train_gender.csv\", index=False)\n",
    "data.Education.to_csv(\"./data/train_education.csv\", index=False)\n",
    "data.QueryList.to_csv(\"./data/train_querylist.csv\", index=False)\n",
    "\n",
    "data = pd.read_csv(testname,encoding='gbk')\n",
    "print (data.info())\n",
    "\n",
    "data.QueryList.to_csv(\"./data/test_querylist.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 finished\n",
      "4000 finished\n",
      "6000 finished\n",
      "8000 finished\n",
      "total time: 305.067053 s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import jieba.analyse\n",
    "import time\n",
    "import jieba\n",
    "import jieba.posseg\n",
    "import os, sys\n",
    "#text segmentation\n",
    "\n",
    "def input(trainname):\n",
    "    traindata = []\n",
    "    with open(trainname, 'rb') as f:\n",
    "        line = f.readline()\n",
    "        count = 0\n",
    "        while line:\n",
    "            try:\n",
    "                traindata.append(line)\n",
    "                count += 1\n",
    "            except:\n",
    "                print (\"error:\", line, count)\n",
    "            line=f.readline()\n",
    "    return traindata\n",
    "#start = time.clock()\n",
    "start = time.perf_counter()\n",
    "\n",
    "filepath = './data/test_querylist.csv'\n",
    "QueryList = input(filepath)\n",
    "\n",
    "writepath = './data/test_querylist_writefile-1w.csv'\n",
    "csvfile = open(writepath, 'w')\n",
    "\n",
    "POS = {}\n",
    "for i in range(len(QueryList)):\n",
    "    #print (i)\n",
    "    if i%2000 == 0 and i >=1000:\n",
    "        print (i,'finished') \n",
    "    s = []\n",
    "    str = \"\"\n",
    "    words = jieba.posseg.cut(QueryList[i])\n",
    "    allowPOS = ['n','v','j']\n",
    "    for word, flag in words:\n",
    "        POS[flag]=POS.get(flag,0)+1\n",
    "        if (flag[0] in allowPOS) and len(word)>=2:\n",
    "            str += word + \" \"\n",
    "            \n",
    "    cur_str = str.encode('utf8')\n",
    "    cur_str = cur_str.decode('utf8')\n",
    "    s.append(cur_str)\n",
    "    \n",
    "    csvfile.write(\" \".join(s)+'\\n')\n",
    "csvfile.close()\n",
    "\n",
    "#end = time.clock()\n",
    "end = time.perf_counter()\n",
    "print (\"total time: %f s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "train_path = './data/train_querylist_writefile-1w.csv'\n",
    "with open(train_path, 'r') as f:\n",
    "    My_list = []\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        cur_list = []\n",
    "        line = line.strip()\n",
    "        data = line.split(\" \")\n",
    "        for d in data:\n",
    "            cur_list.append(d)\n",
    "        My_list.append(cur_list)\n",
    "    \n",
    "    model = word2vec.Word2Vec(My_list, vector_size=300, window=10,workers=4)  \n",
    "    savepath = '1w_word2vec_' + '300'+'.model' \n",
    "\n",
    "    model.save(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('特长生', 0.9320876002311707),\n",
       " ('中国人民大学', 0.8937985897064209),\n",
       " ('北大', 0.8924200534820557),\n",
       " ('北京大学', 0.891645073890686),\n",
       " ('复旦大学', 0.8911810517311096),\n",
       " ('院校', 0.8872029185295105),\n",
       " ('清华大学', 0.8815717101097107),\n",
       " ('录取线', 0.878574788570404),\n",
       " ('南开大学', 0.878221869468689),\n",
       " ('金融学', 0.8778314590454102)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"清华\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim import models\n",
    "#average vector\n",
    "file_name = './data/train_querylist_writefile-1w.csv'\n",
    "cur_model = models.Word2Vec.load('1w_word2vec_300.model')\n",
    "with open(file_name, 'r') as f:\n",
    "    cur_index = 0\n",
    "    lines = f.readlines()\n",
    "    doc_cev = np.zeros((len(lines),300))\n",
    "    for line in lines:\n",
    "        word_vec = np.zeros((1,300))\n",
    "        words = line.strip().split(' ')\n",
    "        wrod_num = 0\n",
    "        for word in words:\n",
    "            #print(words)\n",
    "            if word in cur_model.wv:\n",
    "                wrod_num += 1\n",
    "                word_vec += np.array([cur_model.wv[word]])\n",
    "        doc_cev[cur_index] = word_vec / float(wrod_num)\n",
    "        cur_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "广州 厨宝 烤箱 世情 人情 花易落 风干 泪痕 厦门 酒店用品 批发市场 不想 支付 原谅 无情 处女座 代表 花朵 鸡胸肉 做法 烤箱 忘记 想起 走到 联塑 排水管 规格 大王 性格 文静 意思 牛奶 奶粉 化蝶 芳草 意思 学会 懂得 学会 福睿斯 斗鱼 厨宝 厨宝 烤箱 禹州 城市 广场 电影院 大王 棕树 图片 棕树 图片 发酵 不想 支付 原谅 无情 城市 下雨 有没有 牛奶 奶粉 做法 烤箱 全脂奶粉 比例 牛肉 厨宝牌 猴配猴 婚姻 可惜 爱情 公寓 不住 笑话 太岁 意思 禹州 城市 广场 电影院 禹州 城市 广场 电影院 烤箱 牌子 全脂奶粉 铁人 面粉 蛋白质 含量 活成 样子 鸡排 做法 放爱 斗鱼 直播 糖浆 鸡胸肉 沙枣 轮胎 气压 轮胎 气压 厨宝 牌子 冰皮 月饼 糯米粉 出去 永远都是 生肖 配对 处女座 配对 处女座 相信 世界 冒险 作为 意思 虎牙 直播 联系 想像 联系 瓦一 小时 鸡排 做法 好吃 卡农 故事 开可 不用 道歉 首歌 婚礼 足够 婚礼 厨宝 人生 秋风 悲画 耳朵 图片 空间 视频 厨宝 官网 走到 生肖 配对 高筋 面粉 杨之华 林肯 处女座 男生 特点 感情 紫罗兰 学会 懂得 王棕 龟头 小红点 烤鸡肉 做法 烤箱 邓超 香菇 鸡片 做法 瓦一 小时 瓦一 小时 黄油 阿里巴巴 批发网 和面机 茉香 绿茶 泡法 意大利 烟肉 厨宝 意思 人生路 冰皮 月饼 做法 配方 分手 厨宝 烤箱 价格表 处女座 男生 恋爱 特点 鸡胸肉 做法 全家 牛至 香菇 鸡块 做法 电池 联塑 南瓜 饺子 做法 蝴蝶 兰花 心寒 意思 人生 人生 拖拉机 图片 月饼 比例 鸡胸肉 做法 婚礼 足够 人民币 生肖 代表 轮胎 气压 处女座 男生 恋爱 注意 铁人 面粉 烤鸡肉 做法 触宝 官网 瑞斯 雅格 打喷嚏 吉凶 沙棕 面包 做法 可惜 女人 出轨 女人 烤肉 做法 确定 爱情 公寓 可惜 没有 红豆相思 诗句 月饼 豆沙 做法 土司面包 做法 人生 联系 想像 爱情 摆在 全脂奶粉 罗勒 图片 罗勒 种子 胡子 原因 走过 懂得 烤鱼 烤箱 温度 时间 厨宝牌 烤箱 分手 鸡胸肉 做法 猴子 头像 简笔画 朋友圈 视频 厨宝 烤箱 牌子 相亲 意大利 烟肉 珍珠奶茶 南瓜 做法 出去 永远都是 手扶拖拉机 猴子 头像 椰子树 椰子树 手机 空间 视频 成人高考 时间 茉香 绿茶 酒店用品 批发市场 冰皮 月饼 南瓜 做法 虎牙 直播 观看 铁人 面粉 蛋白质 月亮 奥尔良 做法 轮胎 气压 杨志华 人工 黄油 相思 诗句 文静 意思 处女座 配对 罗勒 碰水 起皱 原因 茉香 绿茶 做法 冰皮 月饼 做法 相信 世界 雅虎 直播 波导 泉州 酒店用品 批发市场 意思 蛋黄 温度 朋友 再见 再见 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x179847dbeb0>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import wordcloud\n",
    "import imageio\n",
    "#word cloud\n",
    "file_name = './data/train_querylist_writefile-1w.csv'\n",
    "\n",
    "font = 'Dengl.ttf'\n",
    "\n",
    "words = ''\n",
    "\n",
    "genderlabel = np.loadtxt(open('./data/train_gender.csv', 'r'), skiprows=1).astype(int)\n",
    "educationlabel = np.loadtxt(open('./data/train_education.csv', 'r'), skiprows=1).astype(int)\n",
    "\n",
    "label = genderlabel\n",
    "index = 2\n",
    "filename = 'gender2' + 'cloud.png'\n",
    "bg_pic =  imageio.imread('gender2.png')\n",
    "#bg_pic =  imageio.imread('female.png')\n",
    "\n",
    "with open(file_name, 'r') as f:\n",
    "    cur_index = 0\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        word_vec = np.zeros((1,300))\n",
    "        \n",
    "        if(label[cur_index] == index):\n",
    "            words = words + line\n",
    "        cur_index += 1  \n",
    "        \n",
    "        if cur_index  == 2:\n",
    "            print(line)\n",
    "        if cur_index > 100:\n",
    "            break\n",
    " \n",
    "#print(words)        \n",
    "c = wordcloud.WordCloud(mask = bg_pic, font_path = font, background_color='white', max_words = 100, repeat = False)\n",
    "c.generate(words)\n",
    "c.to_image()\n",
    "c.to_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9988, 300)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_cev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.28605239,  0.08456552, -0.03387368,  0.40967785, -0.06074544,\n",
       "       -0.19303788,  0.29931122,  0.65367988, -0.35404672,  0.34058462,\n",
       "        0.11514796, -0.29682864,  0.83069158,  0.16118781, -0.21476016,\n",
       "        0.29299607, -0.06404278, -0.20244132,  0.21500196, -0.32999783,\n",
       "       -0.58554488,  0.23107728,  0.15186575, -0.30322209, -0.17741637,\n",
       "        0.04875937, -1.13948402,  0.21164155, -0.01895785, -0.34594541,\n",
       "        0.25041685,  0.2073958 , -0.05585247, -0.1117806 , -0.22181896,\n",
       "        0.6193757 ,  0.13302078, -0.03312266, -0.35758141, -0.02361543,\n",
       "       -0.12798117,  0.14999292, -0.14540141,  0.15569988,  0.28706231,\n",
       "       -0.18069979, -0.04731872, -0.02267059, -0.01743772,  0.37264246,\n",
       "        0.06796043,  0.19068663,  0.06682884, -0.14007489,  0.32452205,\n",
       "        0.21952693,  0.52570341,  0.2173711 ,  0.28917367,  0.28604051,\n",
       "       -0.32838078,  0.37875476, -0.39212239,  0.09687852, -0.17460263,\n",
       "       -0.03972751,  0.11020986, -0.29446618, -0.17828588,  0.12276942,\n",
       "       -0.55309636, -0.44069795, -0.26061105, -0.04149031, -0.33760801,\n",
       "        0.18985088, -0.01408613, -0.3552546 , -0.05157674,  0.32815291,\n",
       "        0.08054153, -0.56781511,  0.44502259,  0.11736212, -0.11512826,\n",
       "        0.07567861,  0.09022965,  0.25819902, -0.35123406,  0.18550498,\n",
       "        0.4955431 ,  0.12126228, -0.23215868,  0.56662595,  0.11193624,\n",
       "        0.1461003 ,  0.30509924, -0.02052514, -0.80273992,  0.42908147,\n",
       "        0.0776343 ,  0.06812993,  0.42197742, -0.13542212, -0.56463235,\n",
       "        0.09752198,  0.15008443,  0.44345775, -0.25766434,  0.09178153,\n",
       "       -0.23970133, -0.23739479, -0.23859701,  0.26296833, -0.04921036,\n",
       "        0.01887316, -0.16803137, -0.52155217,  0.12034275, -0.09863202,\n",
       "       -0.09660511, -0.26498701,  0.20594154, -0.09762841, -0.12608327,\n",
       "        0.3370391 ,  0.50213241, -0.14532465, -0.15152655, -0.05108749,\n",
       "        0.52940826,  0.44941063, -0.14672091, -0.50128522, -0.05098423,\n",
       "        0.10120993,  0.13888087, -0.03519346, -0.81982607,  0.49225762,\n",
       "        0.15379693, -0.40365518, -0.57730841,  0.02992763,  0.47450204,\n",
       "        0.06594196, -0.04287836,  0.35691991, -0.05471177, -0.29718034,\n",
       "        0.47164135, -0.52644547, -0.40293937,  0.00730426, -0.24994162,\n",
       "       -0.11790097, -0.65411044, -0.30943521,  0.08146178,  0.12303555,\n",
       "       -0.3622649 ,  0.16340941, -0.54483791, -0.01277534,  0.35696173,\n",
       "        0.29177782,  0.5317497 ,  0.12325396, -0.06859293,  0.73634914,\n",
       "        0.05056705,  0.32315653, -0.42643743,  0.48202329, -0.30693857,\n",
       "       -0.16328219,  0.08562906, -0.50864673, -0.48705793, -0.08833706,\n",
       "       -0.71155914,  0.18300969, -0.14456787, -0.17825256,  0.09720219,\n",
       "       -0.02357947, -0.01973772,  0.29143713, -0.21493036,  0.26283685,\n",
       "        0.30020073, -0.2521023 , -0.61831552, -0.12816187,  0.089009  ,\n",
       "        0.21022005,  0.36123027, -0.31401864,  0.24908533, -0.22872658,\n",
       "       -0.31143688,  0.06621759, -0.26317834,  0.20140899,  0.12869996,\n",
       "       -0.11936513,  0.1117083 ,  0.40980165,  0.26197278,  0.12848756,\n",
       "        0.35363343, -0.16569266,  0.05875442, -0.33326504, -0.14752125,\n",
       "       -0.39619564,  0.48634881, -0.32438896, -0.68920875,  0.20924466,\n",
       "       -0.04412507,  0.26392741, -0.14719467, -0.30857627, -0.38702826,\n",
       "       -0.61773824,  0.02491133, -0.24373372,  0.12104237,  0.23048614,\n",
       "        0.43084359, -0.35401605,  0.0066058 ,  0.41302666, -0.45515934,\n",
       "        0.14143383,  0.28686314,  0.3947334 , -0.2316748 , -0.79512623,\n",
       "        0.64791927, -0.46828502,  0.29101416,  0.63056866, -0.2029509 ,\n",
       "       -0.15891557, -0.20781904, -0.22643819, -0.16765252, -0.05049906,\n",
       "       -0.08516516,  0.35778119,  0.46685545,  0.11271334, -0.65280873,\n",
       "       -0.35736117,  0.11833803,  0.28464312, -0.47438999,  0.06838306,\n",
       "        0.32212499,  0.23910649,  0.05292336, -0.5194021 , -0.18694453,\n",
       "        0.07110677,  0.16957203,  0.28555323, -0.33046292,  0.46495719,\n",
       "       -0.05575303,  0.33109237,  0.46082778, -0.01577654,  0.44048715,\n",
       "       -0.15690978,  0.76799596, -0.23459596, -0.00443531, -0.1983925 ,\n",
       "        0.24964806,  0.05679435,  0.20420736,  0.09258012,  0.12954041,\n",
       "        0.04268042, -0.26072046,  0.14053918, -0.08769055,  0.56203659,\n",
       "       -0.06519846,  0.36440522,  0.2388109 , -0.36812907,  0.21850706,\n",
       "        0.27063246,  0.31170873,  0.07816084,  0.63926906,  0.45049709])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_cev[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9988,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genderlabel = np.loadtxt(open('./data/train_gender.csv', 'r'), skiprows=1).astype(int)\n",
    "genderlabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9988,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "educationlabel = np.loadtxt(open('./data/train_education.csv', 'r'), skiprows=1).astype(int)\n",
    "educationlabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9988,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agelabel = np.loadtxt(open('./data/train_age.csv', 'r'), skiprows=1).astype(int)\n",
    "agelabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9756, 300) (9756,)\n",
      "(9815, 300) (9815,)\n",
      "(9064, 300) (9064,)\n"
     ]
    }
   ],
   "source": [
    "def removezero(x, y):\n",
    "        nozero = np.nonzero(y)\n",
    "        y = y[nozero]\n",
    "        x = np.array(x)\n",
    "        x = x[nozero]\n",
    "        return x, y\n",
    "gender_train, genderlabel = removezero(doc_cev, genderlabel)\n",
    "age_train, agelabel = removezero(doc_cev, agelabel)\n",
    "education_train, educationlabel = removezero(doc_cev, educationlabel)\n",
    "print (gender_train.shape,genderlabel.shape)\n",
    "print (age_train.shape,agelabel.shape)\n",
    "print (education_train.shape,educationlabel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LK867\\AppData\\Local\\Temp\\ipykernel_65460\\1435954172.py:17: RuntimeWarning: invalid value encountered in true_divide\n",
      "  doc_cev[cur_index] = word_vec / float(wrod_num)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "file_name = './data/test_querylist_writefile-1w.csv'\n",
    "cur_model = models.Word2Vec.load('1w_word2vec_300.model')\n",
    "with open(file_name, 'r') as f:\n",
    "    cur_index = 0\n",
    "    lines = f.readlines()\n",
    "    doc_cev = np.zeros((len(lines),300))\n",
    "    for line in lines:\n",
    "        word_vec = np.zeros((1,300))\n",
    "        words = line.strip().split(' ')\n",
    "        wrod_num = 0\n",
    "        for word in words:\n",
    "            if word in cur_model.wv:\n",
    "                wrod_num += 1\n",
    "                word_vec += np.array([cur_model.wv[word]])\n",
    "        doc_cev[cur_index] = word_vec / float(wrod_num)\n",
    "        cur_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9972, 300)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_cev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.43363786e-02,  4.36613412e-01,  2.84264537e-02, -2.04844711e-02,\n",
       "       -2.35153031e-01, -4.78497279e-01,  2.39278287e-01,  3.87633498e-01,\n",
       "        2.10046680e-02,  1.30885600e-02,  1.76059343e-01, -9.83039028e-02,\n",
       "       -2.13489247e-01,  3.03166624e-01, -1.94200236e-01, -3.96401041e-01,\n",
       "        2.25793197e-01, -8.23055541e-02,  1.33312987e-01,  4.41146614e-02,\n",
       "        7.42870123e-03,  7.89558207e-02,  5.75791957e-01, -4.57384490e-02,\n",
       "        3.01354918e-01,  2.56641772e-02, -1.30405654e-01, -2.20521983e-01,\n",
       "       -2.35177718e-01, -3.69375733e-01,  2.97681757e-02, -2.94269163e-01,\n",
       "       -9.16692546e-02, -7.02136037e-02, -8.12211835e-02,  2.20430628e-01,\n",
       "        1.64288955e-01, -5.49386606e-01,  4.37120331e-02, -1.77976631e-01,\n",
       "        1.76180659e-01,  1.07522886e-02, -3.22695774e-02, -5.22001086e-01,\n",
       "       -5.28454662e-02,  3.23612767e-01, -1.64170810e-02, -7.11515662e-03,\n",
       "        4.80080634e-02, -2.60805020e-01, -2.85780312e-01, -8.99825666e-02,\n",
       "       -2.10516920e-01,  2.71972482e-01, -1.48476311e-01,  3.01194891e-01,\n",
       "        2.07604972e-01,  1.83418365e-01,  5.47283499e-02,  2.48489245e-02,\n",
       "       -2.90469768e-02, -3.88707763e-01, -1.65147502e-02,  2.22964498e-01,\n",
       "        1.33708853e-01,  8.90099463e-03, -8.70759483e-02,  1.46711437e-01,\n",
       "       -1.95579897e-01,  2.18167010e-01,  2.43812286e-01,  1.52085821e-01,\n",
       "        2.90321134e-01, -1.77171922e-01, -9.79249656e-02, -1.23519270e-01,\n",
       "       -1.22261203e-01, -3.54520939e-03, -1.13500654e-01,  9.34402998e-02,\n",
       "       -1.03289009e-01, -1.67368454e-01,  1.66132228e-01,  5.55823023e-01,\n",
       "        1.74380845e-01, -3.55842670e-02, -3.24839044e-01,  2.22772683e-01,\n",
       "        3.05256034e-01,  1.19941954e-01,  1.30002278e-01,  4.90156241e-02,\n",
       "        5.34661320e-02, -3.60055635e-01,  1.29641007e-01,  1.53479486e-01,\n",
       "        3.22186116e-01,  8.86301518e-02,  9.70916426e-02,  1.38598796e-01,\n",
       "       -4.38236850e-02,  2.96711765e-04, -1.92009777e-01,  5.07888251e-02,\n",
       "        2.37119566e-01,  2.75718786e-01, -1.41205512e-01, -1.52072874e-01,\n",
       "       -1.10448698e-01,  7.97529507e-03,  9.91561719e-02, -1.05820618e-01,\n",
       "        1.18580661e-01,  1.19549599e-01,  7.37052175e-03, -4.01193255e-02,\n",
       "       -1.75497255e-01, -8.84493587e-02,  4.13712916e-01, -2.59182949e-01,\n",
       "        1.46057017e-01, -2.34973873e-01,  1.82933844e-01, -9.55044318e-02,\n",
       "        1.53929428e-01,  1.68039617e-02,  1.33044503e-01, -1.77168940e-01,\n",
       "       -2.00581020e-01,  1.50838839e-01,  1.61380643e-01,  2.40148802e-01,\n",
       "       -5.40571107e-03,  1.21050908e-02, -1.16765356e-01, -2.80958057e-01,\n",
       "        1.41783203e-01, -2.04502440e-01,  3.01968571e-02, -3.99453322e-01,\n",
       "        2.31530156e-02,  4.17432849e-02,  3.21476645e-01,  7.40260986e-02,\n",
       "       -2.83045831e-02, -2.55732331e-01, -5.00029630e-01, -1.13308274e-01,\n",
       "        9.07676534e-02, -2.49368696e-01,  6.11503667e-02, -3.89217119e-01,\n",
       "        3.46468805e-02, -1.56903406e-01,  7.90250047e-02,  1.16008368e-01,\n",
       "       -1.21963693e-01,  1.42503005e-01, -5.77415612e-02,  2.64300460e-01,\n",
       "        1.59253460e-01,  1.53615904e-02,  1.95057337e-02,  1.49756942e-01,\n",
       "       -2.58520269e-01, -1.91672230e-01,  5.46077385e-02, -3.15041164e-01,\n",
       "       -1.44405879e-01,  1.89946867e-01, -1.99345130e-01, -4.50843374e-02,\n",
       "        1.34481945e-01,  1.33942961e-01,  1.01864815e-01, -1.25905429e-01,\n",
       "        3.29044563e-03, -3.84122954e-01,  1.44614919e-01, -1.18630890e-01,\n",
       "       -5.27414129e-02, -5.24642716e-02, -1.07313746e-01, -2.71605225e-01,\n",
       "       -2.65003729e-01,  8.46651088e-02,  3.35317773e-01,  2.11587738e-01,\n",
       "        1.01240199e-01, -3.72833241e-01,  4.40802786e-03,  2.48622076e-01,\n",
       "       -8.30738233e-02, -1.30573677e-01,  1.11691836e-01, -8.87757091e-02,\n",
       "       -2.00414936e-01, -3.81144072e-01,  2.09016822e-01, -9.15860980e-02,\n",
       "       -1.53922674e-01,  3.21997323e-01, -2.96650500e-01, -3.08878485e-01,\n",
       "       -3.87282427e-02, -3.95146221e-02, -1.57026151e-02,  2.14972804e-01,\n",
       "       -2.30923966e-01, -8.81815543e-02, -2.72661995e-01, -2.83187511e-01,\n",
       "       -1.74341622e-01, -4.46082784e-01,  6.36614258e-02, -4.41448819e-01,\n",
       "       -3.16151303e-01, -5.40682162e-01,  1.26741973e-01, -3.73942545e-01,\n",
       "       -1.92050759e-01, -1.37248939e-02, -5.26722983e-02, -2.68796473e-01,\n",
       "       -4.18016904e-02,  2.33672596e-01,  2.78490624e-02,  8.68762878e-02,\n",
       "       -2.57054428e-01, -1.74810700e-01, -2.14416412e-02,  1.50939626e-01,\n",
       "       -1.11825635e-01, -1.18442494e-01, -2.17959326e-01,  2.80807351e-03,\n",
       "        4.26583408e-02,  5.18975929e-02,  5.39081782e-02, -7.36076740e-02,\n",
       "       -8.30057465e-02, -2.61238207e-01,  2.28537409e-04, -9.23016107e-02,\n",
       "       -1.15788069e-01, -3.74503983e-01, -1.55649126e-02, -3.77981022e-02,\n",
       "        8.31573230e-02,  2.34015022e-01,  4.91118674e-01, -1.18274447e-01,\n",
       "        4.08264055e-02,  1.57615505e-01, -2.43067508e-01, -2.26363203e-01,\n",
       "        3.68260660e-01,  1.02981867e-01, -5.53386735e-02, -1.61418742e-01,\n",
       "       -2.69962826e-02, -4.75731776e-02,  7.68444249e-02, -1.46787187e-02,\n",
       "        6.22700992e-02,  9.09720744e-02, -5.68105632e-02, -2.72311189e-02,\n",
       "        1.05531599e-01,  2.80354448e-02, -1.71016687e-01, -1.76895750e-02,\n",
       "       -2.81015513e-01, -1.88739047e-01,  2.24245673e-01,  1.53218955e-02,\n",
       "       -1.56596353e-01,  2.23368542e-01, -1.33753307e-01,  1.71748755e-01,\n",
       "        1.93622087e-01,  2.39095031e-01, -2.20974493e-01,  4.83308383e-02,\n",
       "        1.37749246e-01,  1.74167476e-02, -3.49422909e-01,  2.76459718e-01,\n",
       "       -5.12041404e-02,  3.45690747e-01, -6.18817955e-02,  3.17773449e-01,\n",
       "        2.50675275e-01, -2.14159973e-02,  1.78615704e-01,  5.63725230e-01,\n",
       "        9.93324649e-02, -1.48088727e-01,  2.14408549e-01, -2.36109640e-01])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_cev[6]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
